{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aAI1FURLjt4X",
   "metadata": {
    "id": "aAI1FURLjt4X"
   },
   "source": [
    "# Creating a recommender system with RNNs\n",
    "\n",
    "We will observe the history of items that customers have bought from our online store. Our objective is to predict the next item that a customer will buy, given their purchase history.\n",
    "\n",
    "**Question 1**: Assuming you can predict well what customers are going to buy when visiting our store. What can you do with this information in order to improve the profits of our online store?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79621202",
   "metadata": {},
   "source": [
    "With this information, an online store can improve profits in many ways. A few examples are: offer personalized product recommendations to customers, implement dynamic pricing strategies and manage inventory a lot more efficiently. Additionally, in relation with this assignment of predicting what customers will buy next given their history, the product recommendations and dynamic pricing will specifically be focused on what a costumer is predicted to by next. For example, if a cotue=mer bought a pregnancy test, the next logical recoomendation would be baby supplies and then deals on baby supply bundles could be offered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9b7631",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T15:26:45.148692Z",
     "start_time": "2024-03-27T15:26:20.726851Z"
    },
    "id": "6c9b7631"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, BatchNormalization, GRU, Dense\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hv2XW-dRjzki",
   "metadata": {
    "id": "hv2XW-dRjzki"
   },
   "source": [
    "## 1. The data\n",
    "\n",
    "Each entry in the dataset corresponds to a combination of customer and item bought. Per customer, items are arranged based on the visits to our online store (e.g., customer 17850 first bought item 0, then item 399, then item 505, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdf310c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T15:26:52.110158Z",
     "start_time": "2024-03-27T15:26:48.020842Z"
    },
    "id": "9cdf310c"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://www.dropbox.com/s/4kicl5okwlmst5i/online_retail.csv?dl=1')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZZvSj9QfbinS",
   "metadata": {
    "id": "ZZvSj9QfbinS"
   },
   "source": [
    "We will later use zero-padding to get sequences of equal length. Hence, we should avoid items with name \"0\" and instead shift all items by 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddPc8BCH9yV",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T15:26:53.343955Z",
     "start_time": "2024-03-27T15:26:53.327308Z"
    },
    "id": "eddPc8BCH9yV"
   },
   "outputs": [],
   "source": [
    "df['StockCode'] = df['StockCode'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4970c79c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T15:26:53.693240Z",
     "start_time": "2024-03-27T15:26:53.657154Z"
    },
    "id": "4970c79c"
   },
   "outputs": [],
   "source": [
    "number_items = len(df['StockCode'].unique())\n",
    "number_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da28a000",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T15:26:54.453569Z",
     "start_time": "2024-03-27T15:26:54.444308Z"
    }
   },
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WeKafihlk0UI",
   "metadata": {
    "id": "WeKafihlk0UI"
   },
   "source": [
    "We convert the dataframe into a list of sequences, where each customer corresponds to one sequence of items bought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308a0b3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T15:27:00.615681Z",
     "start_time": "2024-03-27T15:26:55.537029Z"
    },
    "id": "308a0b3b"
   },
   "outputs": [],
   "source": [
    "sequences = []\n",
    "for customer in df['CustomerID'].unique():\n",
    "    temp = df[df['CustomerID'] == customer]\n",
    "    sequences.append(temp['StockCode'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "K8mdeMoMk9YQ",
   "metadata": {
    "id": "K8mdeMoMk9YQ"
   },
   "source": [
    "Some sequences are much longer than others, so we will only consider sequences of a certain length. In particular, we pick here approximately the 90% quantile to cut off sequences of purchases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ee9767",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T15:27:01.941379Z",
     "start_time": "2024-03-27T15:27:01.910876Z"
    },
    "id": "c5ee9767"
   },
   "outputs": [],
   "source": [
    "np.quantile([len(seq) for seq in sequences],0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95d8678",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T15:27:02.520861Z",
     "start_time": "2024-03-27T15:27:02.493859Z"
    },
    "id": "f95d8678"
   },
   "outputs": [],
   "source": [
    "max_length = 160\n",
    "sequences = [seq[:min(max_length,len(seq))] for seq in sequences]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0599HYqlH1B",
   "metadata": {
    "id": "d0599HYqlH1B"
   },
   "source": [
    "We also add \"padding\" to make sequences of equal length (to train our model, each sequence within a mini-batch has to have the same length. Since we don't want to have a lot of work splitting the data into mini-batches, we will just equalize everything). Note that we will need to tell our algorithm later to ignore padded values when it comes to loss-computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b11131",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T15:27:10.650300Z",
     "start_time": "2024-03-27T15:27:10.637388Z"
    },
    "id": "42b11131"
   },
   "outputs": [],
   "source": [
    "sequences[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7262f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T15:27:10.962135Z",
     "start_time": "2024-03-27T15:27:10.880317Z"
    },
    "id": "fe7262f9"
   },
   "outputs": [],
   "source": [
    "sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences, padding=\"pre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07867de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T15:27:11.482440Z",
     "start_time": "2024-03-27T15:27:11.469742Z"
    },
    "id": "b07867de",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sequences[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d8d58e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T15:27:12.371274Z",
     "start_time": "2024-03-27T15:27:12.360822Z"
    }
   },
   "outputs": [],
   "source": [
    "len(sequences[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cyrgoaqm3en",
   "metadata": {
    "id": "5cyrgoaqm3en"
   },
   "source": [
    "Next, we split the data into training, validation, and testing (randomly):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EZUe69DeT2sN",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T15:27:13.585924Z",
     "start_time": "2024-03-27T15:27:13.561168Z"
    },
    "id": "EZUe69DeT2sN"
   },
   "outputs": [],
   "source": [
    "X_train, X_other = train_test_split(sequences,train_size=0.8)\n",
    "X_valid, X_test = train_test_split(X_other,train_size=0.5)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32d3309",
   "metadata": {},
   "source": [
    "Finally, we build our target (y) based on a sequence-to-sequence approach. That is, for each sequence of inputs, we predict a sequence of outputs.\n",
    "\n",
    "**Question 2**: Below, we construct the variables `y_train`, `y_valid`, and `y_test`. Describe why we build the `y` variables in this way and why we also need to modify `X_train`, `X_valid`, and `X_test`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d48294",
   "metadata": {},
   "source": [
    "To create y_train, y_valid, and y_test, we are simply taking only the last element of the sequence for the corresponding X_train, X_valid, and X_test. This last element is the element will be trying to predict based on the previous sequence. For X_train, X_valid, and X_test, we need to remove the last element as it is the one we are trying to predict and should not be part of the input sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9624434",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T15:27:15.178878Z",
     "start_time": "2024-03-27T15:27:15.156531Z"
    },
    "id": "b9624434"
   },
   "outputs": [],
   "source": [
    "y_train = X_train[:,1:]\n",
    "y_valid = X_valid[:,1:]\n",
    "y_test = X_test[:,1:]\n",
    "\n",
    "X_train = X_train[:,:-1]\n",
    "X_valid = X_valid[:,:-1]\n",
    "X_test = X_test[:,:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b25531",
   "metadata": {},
   "source": [
    "Check your sequence lengths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292bb29a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T15:27:16.438062Z",
     "start_time": "2024-03-27T15:27:16.428322Z"
    }
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "M7FsxQEHm_xx",
   "metadata": {
    "id": "M7FsxQEHm_xx"
   },
   "source": [
    "## 2. Building a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4183da97",
   "metadata": {},
   "source": [
    "We now build a model that takes as input a sequence of orders by one customer and outputs the predictions for the next time step. Instead of directly using our sequences as inputs to a recurrent layer, we will use an `Embedding` layer.\n",
    "\n",
    "**Question 3**: In your own words, describe what (word) embeddings do, and why we use them in deep learning. A good resource is the accompanying book \"Deep Learning with Python\" (2nd edition) by Francois Chollet, available online through the City University Library. You might want to check the part \"Understanding Word Embeddings\" within Chapter 11.3.3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c309f14",
   "metadata": {},
   "source": [
    "From my understanding, embeddings encode the meaning of words or in our case stock codes into vector representations with relatively low dimensionalty. They are essentially doing the same job as one-hot encoding categorical variables, except at a fixed lower dimensionality which for this model we choose to be 6. During training, the model adjusts these embeddings to increase its performance. When adjusting these embeddings, the model makes products (stock codes) which are similiar to have vectors that are closer together in the embedding space and allows the model capture relationships between these codes to help predict the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QzAk-wbMbz9z",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T15:27:21.878102Z",
     "start_time": "2024-03-27T15:27:19.862254Z"
    },
    "id": "QzAk-wbMbz9z"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    Embedding(input_dim=number_items+1, output_dim=6, input_shape=[None], mask_zero=True),\n",
    "    Conv1D(32, kernel_size=2, padding=\"causal\", activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    GRU(64, return_sequences=True, dropout = 0.2),\n",
    "    BatchNormalization(),\n",
    "    Dense(number_items+1, activation=\"softmax\")\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jeiqtGhXLPg3",
   "metadata": {
    "id": "jeiqtGhXLPg3"
   },
   "source": [
    "We want to add our own metric, to capture how well we're doing on the last prediction (that's the only one that matters after all). In particular, we will see whether the product the customer bought is within the 5 products we gave the highest probability in our prediction.\n",
    "\n",
    "**Question 4**: Define a function `last_time_step_top_5` that takes the inputs `y_true` and `y_pred` and computes the `tf.keras.metrics.sparse_top_k_categorical_accuracy` between `y_true` and `y_pred` *for the last entry of each sequence*. Note that `sparse_top_k_categorical_accuracy` (see the [documentation here](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/sparse_top_k_categorical_accuracy)) takes as input the (modified) `y_true` and `y_pred`, as well as a value `k`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mtL6xq4o-2r_",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T15:27:26.200281Z",
     "start_time": "2024-03-27T15:27:26.191314Z"
    },
    "id": "mtL6xq4o-2r_"
   },
   "outputs": [],
   "source": [
    "def last_time_step_top_5(y_true, y_pred):\n",
    "    \n",
    "    last_true = tf.gather(y_true, tf.shape(y_true)[0] - 1, axis=0)\n",
    "    last_pred = tf.gather(y_pred, tf.shape(y_pred)[0] - 1, axis=0)\n",
    "    \n",
    "    return tf.keras.metrics.sparse_top_k_categorical_accuracy(last_true, last_pred, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JlVSMayCLVn5",
   "metadata": {
    "id": "JlVSMayCLVn5"
   },
   "source": [
    "We are now ready to train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DmVSCZw5_AgL",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T15:36:42.549549Z",
     "start_time": "2024-03-27T15:27:28.711971Z"
    },
    "id": "DmVSCZw5_AgL",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
    "                metrics = [last_time_step_top_5])\n",
    "log = model.fit(X_train, y_train, epochs=20,\n",
    "                validation_data = (X_valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfba1dcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T15:40:18.737176Z",
     "start_time": "2024-03-27T15:40:18.737176Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get predictions on training data\n",
    "y_pred_train = model.predict(X_train)\n",
    "\n",
    "# Get predictions on validation data\n",
    "y_pred_valid = model.predict(X_valid)\n",
    "\n",
    "#Get predictions on test data\n",
    "y_pred_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59e408b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T23:39:33.671260Z",
     "start_time": "2024-03-26T23:39:33.430972Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy_top_5 = last_time_step_top_5(y_train,y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3245b20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T23:39:35.707418Z",
     "start_time": "2024-03-26T23:39:34.456903Z"
    }
   },
   "outputs": [],
   "source": [
    "sum(accuracy_top_5)/len(accuracy_top_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5e5cf0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T23:41:51.168946Z",
     "start_time": "2024-03-26T23:41:51.159831Z"
    }
   },
   "outputs": [],
   "source": [
    "val_accuracy_top_5 = last_time_step_top_5(y_valid,y_pred_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceba955b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T23:42:09.680549Z",
     "start_time": "2024-03-26T23:42:09.543692Z"
    }
   },
   "outputs": [],
   "source": [
    "sum(val_accuracy_top_5)/len(val_accuracy_top_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39097727",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T23:44:40.727729Z",
     "start_time": "2024-03-26T23:44:40.717693Z"
    }
   },
   "outputs": [],
   "source": [
    "test_accuracy_top_5 = last_time_step_top_5(y_test,y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbd6899",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T23:45:00.384058Z",
     "start_time": "2024-03-26T23:45:00.196921Z"
    }
   },
   "outputs": [],
   "source": [
    "#test Accuracy\n",
    "sum(test_accuracy_top_5)/len(test_accuracy_top_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b32a02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T15:37:17.401784Z",
     "start_time": "2024-03-27T15:37:16.114727Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(log.history['last_time_step_top_5'],label = \"actual in top 5 - training\",color='green')\n",
    "plt.plot(log.history['val_last_time_step_top_5'], label = \"actual in top 5 - validation\",color='grey')\n",
    "plt.legend()\n",
    "ax = plt.gca()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cKiB9jncPLFr",
   "metadata": {
    "id": "cKiB9jncPLFr"
   },
   "source": [
    "On the one hand, this doesn't sound too impressive. On the other hand, keep in mind that we have looked at raw items, and 1000 of them (while only having the buying history of 3500 customers)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca4e875",
   "metadata": {
    "id": "HTjV92hnxpPg"
   },
   "source": [
    "**Question 5**: Can you do better? Go through the frameworks we have discussed in class in order to generate an improved model. A few hints:\n",
    "- Before thinking about our framework for improving bias and variance, note that the model does not yet really overfit\n",
    "- While we generally don't stack recurrent layers too deeply for computational reasons, we are currently only using a single one\n",
    "- Consider the specific type of dropout regularization relevant for RNNs\n",
    "- Aside from the typical suspects for parameters to modify, the number of dimensions of the embedding usually has a big influence\n",
    "\n",
    "At the end of your improvement process, evaluate your model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6922ea6",
   "metadata": {},
   "source": [
    "In my new model, i added one more recurrent layer, increased both RNN layers to double, increased the dimensions of embedding to 8, doubled the number of convolution layers and added dropout regularization relevant for RNNs by using reccurent_dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca9cd8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T15:37:53.785504Z",
     "start_time": "2024-03-27T15:37:52.263311Z"
    },
    "id": "QzAk-wbMbz9z",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    Embedding(input_dim=number_items+1, output_dim=8, input_shape=[None], mask_zero=True),\n",
    "    Conv1D(64, kernel_size=2, padding=\"causal\", activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    GRU(128, return_sequences=True, dropout = 0.2, recurrent_dropout=0.2),\n",
    "    GRU(128, return_sequences=True, dropout = 0.2, recurrent_dropout=0.2),\n",
    "    BatchNormalization(),\n",
    "    Dense(number_items+1, activation=\"softmax\")\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e912991",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T15:40:18.726133Z",
     "start_time": "2024-03-27T15:38:05.112470Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
    "                metrics = [last_time_step_top_5])\n",
    "log = model.fit(X_train, y_train, epochs=10,\n",
    "                validation_data = (X_valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3cc601",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T23:44:00.507526Z",
     "start_time": "2024-03-26T23:43:48.160482Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get predictions on training data\n",
    "y_pred_train = model.predict(X_train)\n",
    "\n",
    "# Get predictions on validation data\n",
    "y_pred_valid = model.predict(X_valid)\n",
    "\n",
    "#Get predictions on test data\n",
    "y_pred_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a72d298",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T23:39:33.671260Z",
     "start_time": "2024-03-26T23:39:33.430972Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy_top_5 = last_time_step_top_5(y_train,y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04b37a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T23:39:35.707418Z",
     "start_time": "2024-03-26T23:39:34.456903Z"
    }
   },
   "outputs": [],
   "source": [
    "sum(accuracy_top_5)/len(accuracy_top_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4d25b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T23:41:51.168946Z",
     "start_time": "2024-03-26T23:41:51.159831Z"
    }
   },
   "outputs": [],
   "source": [
    "val_accuracy_top_5 = last_time_step_top_5(y_valid,y_pred_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eee55f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T23:42:09.680549Z",
     "start_time": "2024-03-26T23:42:09.543692Z"
    }
   },
   "outputs": [],
   "source": [
    "sum(val_accuracy_top_5)/len(val_accuracy_top_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb585b6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T23:44:40.727729Z",
     "start_time": "2024-03-26T23:44:40.717693Z"
    }
   },
   "outputs": [],
   "source": [
    "test_accuracy_top_5 = last_time_step_top_5(y_test,y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b027937",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T23:45:00.384058Z",
     "start_time": "2024-03-26T23:45:00.196921Z"
    }
   },
   "outputs": [],
   "source": [
    "#test accuracy\n",
    "sum(test_accuracy_top_5)/len(test_accuracy_top_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c70db04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T23:39:41.197188Z",
     "start_time": "2024-03-26T23:39:40.921889Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(log.history['last_time_step_top_5'],label = \"actual in top 5 - training\",color='green')\n",
    "plt.plot(log.history['val_last_time_step_top_5'], label = \"actual in top 5 - validation\",color='grey')\n",
    "plt.legend()\n",
    "ax = plt.gca()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ADL_Week 10_Recommender RNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
